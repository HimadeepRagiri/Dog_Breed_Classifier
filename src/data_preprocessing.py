# -*- coding: utf-8 -*-
"""data_preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/176e8k3n3EpL11DpvRc_YFfXOlLby9kjK
"""

import os
import scipy.io
from PIL import Image
from torch.utils.data import Dataset, random_split
import torchvision.transforms as transforms

class StanfordDogsDataset(Dataset):
    def __init__(self, images_dir, annotations_dir, transform=None):
        self.images_dir = images_dir
        self.annotations_dir = annotations_dir
        self.transform = transform

        self.labels = self.load_annotations()
        self.breeds = sorted(os.listdir(images_dir))

        self.image_paths = []
        self.image_labels = []

        for breed in self.breeds:
            breed_path = os.path.join(self.images_dir, breed)
            breed_images = os.listdir(breed_path)
            for img_name in breed_images:
                self.image_paths.append(os.path.join(breed_path, img_name))
                self.image_labels.append(self.breeds.index(breed))

    def load_annotations(self):
        breed_annotations = {}
        for breed_folder in os.listdir(self.annotations_dir):
            breed_path = os.path.join(self.annotations_dir, breed_folder)
            if os.path.isdir(breed_path):
                annotation_file = os.path.join(breed_path, 'annotation.mat')
                if os.path.exists(annotation_file):
                    mat_data = scipy.io.loadmat(annotation_file)
                    annotations = mat_data.get('annotations', None)
                    if annotations is not None:
                        breed_annotations[breed_folder] = annotations[0, :]
        return breed_annotations

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image_path = self.image_paths[idx]
        label = self.image_labels[idx]
        image = Image.open(image_path).convert('RGB')
        if self.transform:
            image = self.transform(image)
        return image, label


def get_transforms():
    train_transforms = transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(30),
        transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.8, 1.2)),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    test_transforms = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    return train_transforms, test_transforms


def prepare_data(images_dir, annotations_dir, train_transforms, test_transforms, split_ratio=0.8):
    dataset = StanfordDogsDataset(images_dir, annotations_dir)
    train_size = int(split_ratio * len(dataset))
    test_size = len(dataset) - train_size
    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])

    train_dataset.dataset.transform = train_transforms
    test_dataset.dataset.transform = test_transforms

    return train_dataset, test_dataset