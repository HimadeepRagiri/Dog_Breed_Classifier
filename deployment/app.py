# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BQ7C-ipWLELdYjOQ9IgLYy6Y0Wcl8fO4
"""

from flask import Flask, request, jsonify, render_template_string
from pyngrok import ngrok
import torch
from PIL import Image
import os
from torchvision import transforms
import base64
from io import BytesIO
from model import initialize_model
from utils import load_checkpoint
from torch.optim.lr_scheduler import ReduceLROnPlateau

# Flask app
app = Flask(__name__)

# User-specific configurations
IMAGES_DIR = "path_to_images_directory"  # Replace with the actual path where images are stored
MODEL_PATH = "path_to_model_checkpoint.pth"  # Replace with the actual path to the model checkpoint
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Initialize and Load the model
num_classes = 120
learning_rate = 0.001

model, criterion, optimizer = initialize_model(num_classes, learning_rate)
scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)
model = model.to(DEVICE)
_, _, _, _, _ = load_checkpoint(model, optimizer, scheduler, MODEL_PATH)

model.eval()

# Get breed names from directories
breed_names = sorted(os.listdir(IMAGES_DIR))

# Define image transformations
test_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

@app.route("/", methods=["GET", "POST"])
def index():
    if request.method == "POST":
        # Check if an image was uploaded
        if "file" not in request.files:
            return "No file uploaded", 400
        file = request.files["file"]

        if file.filename == "":
            return "No file selected", 400

        # Process the uploaded image
        image = Image.open(file).convert('RGB')
        image_tensor = test_transforms(image).unsqueeze(0).to(DEVICE)

        # Make prediction
        with torch.no_grad():
            outputs = model(image_tensor)
        _, predicted_class = torch.max(outputs, 1)
        predicted_class = predicted_class.item()
        predicted_breed = breed_names[predicted_class]

        # Convert image to base64 for HTML rendering
        buffer = BytesIO()
        image.save(buffer, format="JPEG")
        buffer.seek(0)
        image_data = base64.b64encode(buffer.read()).decode("utf-8")

        # Render result
        return render_template_string("""
            <!DOCTYPE html>
            <html>
            <head>
                <title>Prediction Result</title>
            </head>
            <body>
                <h1>Prediction Result</h1>
                <img src="data:image/jpeg;base64,{{ image_data }}" alt="Dog Image" style="max-width: 100%; height: auto;">
                <h2>Predicted Breed: {{ breed }}</h2>
                <a href="/">Upload Another Image</a>
            </body>
            </html>
        """, breed=predicted_breed, image_data=image_data)

    # HTML form for image upload
    return """
        <!DOCTYPE html>
        <html>
        <head>
            <title>Dog Breed Prediction</title>
        </head>
        <body>
            <h1>Upload a Dog Image</h1>
            <form action="/" method="post" enctype="multipart/form-data">
                <input type="file" name="file" accept="image/*" required>
                <button type="submit">Predict</button>
            </form>
        </body>
        </html>
    """

# Start ngrok tunnel
public_url = ngrok.connect(5000)
print("ngrok tunnel URL:", public_url)

if __name__ == "__main__":
    app.run()